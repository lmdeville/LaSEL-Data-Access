{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b38b401-5c0d-4400-a895-a2b247108e69",
   "metadata": {},
   "source": [
    "@author Lelia Deville\n",
    "@date 3/9/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f206bc-51d9-42d1-bcd9-f3197c43a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pypyodbc as odbc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "defining set of functions used to read data in LNDB format at LaSEL\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def connect_server(driver_name, server_name, database_name, uid, password):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    driver_name : should be SQL Server, unless this changes\n",
    "    server_name : name of host computer, typically using 192.168.1.109 or PARTLABHMI\n",
    "    database_name : depends on what data is wanted; for LNDB format it should be EI\n",
    "    uid : this could be unique or shared across student groups, see Robert if unknown\n",
    "    password : this could be unique or shared across student groups, see Robert if unknown\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cursor : object used to query into databases\n",
    "    \"\"\"\n",
    "    \n",
    "    connection_string = f\"\"\"\n",
    "    DRIVER={{{driver_name}}};\n",
    "    SERVER={server_name};\n",
    "    DATABASE={database_name};\n",
    "    Trust_Connection =yes;\n",
    "    uid={uid};\n",
    "    pwd={password};\n",
    "    \"\"\"\n",
    "    conn = odbc.connect(connection_string)\n",
    "\n",
    "    return conn.cursor()\n",
    "\n",
    "\n",
    "def read_one_table(cursor, table_name, start, end, columns=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    cursor: cursor object used to query in databases, obtained by running 'connect_server' function above\n",
    "    table_name : name of table in database to read data from\n",
    "    start : date to start query. note: if the query is started before data is recorded or available,\n",
    "    the first datapoint will be when data is actually available, assuming it is before the end date\n",
    "    end : date to end query. note: if the data ends before the query date, the last datapoint will be the final\n",
    "    recorded datapoint, not the end date.\n",
    "    columns : optional. if you only want certain columns from the df, then specify in the form of a constant string\n",
    "    example - 'tmstamp,ws_ms_avg,rh,diffused_avg,dni_avg,global_avg,poa_avg,cmp10poa_avg,cmp10_2_poa_avg'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : df of data with all (or specified) columns within the start and end window\n",
    "    the returned df is localized to LaSEL timezone\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if columns:\n",
    "        cols = columns\n",
    "        col_names = ', '.join(cols)\n",
    "        cursor.execute(f\"select {col_names} from {table_name} where TmStamp between '{start}' and '{end}';\")\n",
    "        data = []\n",
    "        for row in cursor:\n",
    "            data.append(row)\n",
    "        num_fields = len(cursor.description)\n",
    "        field_names = ([i[0] for i in cursor.description])\n",
    "        df = pd.DataFrame(data, columns=[field_names])\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "        df.index = pd.to_datetime(df['tmstamp'])\n",
    "        df.index = df.index.tz_localize('America/Chicago', ambiguous=True, nonexistent='shift_forward')\n",
    "        df.drop(columns='tmstamp', inplace=True)\n",
    "    else:\n",
    "        cursor.execute(f\"select * from {table_name} where TmStamp between '{start}' and '{end}';\")\n",
    "        data = []\n",
    "        for row in cursor:\n",
    "            data.append(row)\n",
    "        num_fields = len(cursor.description)\n",
    "        field_names = ([i[0] for i in cursor.description])\n",
    "        df = pd.DataFrame(data, columns=[field_names])\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "        df.index = pd.to_datetime(df['tmstamp'])\n",
    "        df.index = df.index.tz_localize('America/Chicago', ambiguous=True, nonexistent='shift_forward')\n",
    "        df.drop(columns='tmstamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_two_tables(cursor, table1, table2, start, end, cols1 = None, cols2 = None):\n",
    "     \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    cursor: cursor object used to query in databases, obtained by running 'connect_server' function above\n",
    "    table1 : name of first table in database to read data from\n",
    "    table2: name of second table in database to read data from\n",
    "    start : date to start query. note: if the query is started before data is recorded or available,\n",
    "    the first datapoint will be when data is actually available, assuming it is before the end date\n",
    "    end : date to end query. note: if the data ends before the query date, the last datapoint will be the final\n",
    "    recorded datapoint, not the end date.\n",
    "    cols1 : optional. if you only want certain columns from the first df, then specify in the form of a constant string\n",
    "    example - 'tmstamp,ws_ms_avg,rh,diffused_avg,dni_avg,global_avg,poa_avg,cmp10poa_avg,cmp10_2_poa_avg'\n",
    "    cols2 : optional. columns to use from second table\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : df of data with all (or specified) columns from both tables merged within the start and\n",
    "    end window. note the returned df is localized to LaSEL timezone\n",
    "    \"\"\"\n",
    "    \n",
    "     if cols1:\n",
    "          cols1 = cols1\n",
    "          col_names = ', '.join(cols1)\n",
    "          cursor.execute(f\"select {col_names} from {table1} where TmStamp between '{start}' and '{end}';\")\n",
    "          data = []\n",
    "          for row in cursor:\n",
    "              data.append(row)\n",
    "          num_fields = len(cursor.description)\n",
    "          field_names = ([i[0] for i in cursor.description])\n",
    "          df1 = pd.DataFrame(data, columns=[field_names])\n",
    "          df1.columns = df1.columns.get_level_values(0)\n",
    "          df1.index = pd.to_datetime(df1['tmstamp'])\n",
    "          df1.index = df1.index.tz_localize('America/Chicago', ambiguous=True, nonexistent='shift_forward')\n",
    "          df1.drop(columns='tmstamp', inplace=True)\n",
    "\n",
    "     else:\n",
    "          cursor.execute(f\"select * from {table1} where TmStamp between '{start}' and '{end}';\")\n",
    "          data = []\n",
    "          for row in cursor:\n",
    "               data.append(row)\n",
    "          num_fields = len(cursor.description)\n",
    "          field_names = ([i[0] for i in cursor.description])\n",
    "          df1 = pd.DataFrame(data, columns=[field_names])\n",
    "          df1.columns = df1.columns.get_level_values(0)\n",
    "          df1.index = pd.to_datetime(df1['tmstamp'])\n",
    "          df1.index = df1.index.tz_localize('America/Chicago', ambiguous=True, nonexistent='shift_forward')\n",
    "          df1.drop(columns='tmstamp', inplace=True)\n",
    "\n",
    "     if cols2:\n",
    "          cols2 = cols2\n",
    "          col_names = ', '.join(cols2)\n",
    "          cursor.execute(f\"select {col_names} from {table2} where TmStamp between '{start}' and '{end}';\")\n",
    "          data = []\n",
    "          for row in cursor:\n",
    "               data.append(row)\n",
    "          num_fields = len(cursor.description)\n",
    "          field_names = ([i[0] for i in cursor.description])\n",
    "          df2 = pd.DataFrame(data, columns=[field_names])\n",
    "          df2.columns = df2.columns.get_level_values(0)\n",
    "          df2.index = pd.to_datetime(df2['tmstamp'])\n",
    "          df2.index = df2.index.tz_localize('America/Chicago', ambiguous=True, nonexistent='shift_forward')\n",
    "          df2.drop(columns='tmstamp', inplace=True)\n",
    "     else:\n",
    "          cursor.execute(f\"select * from {table2} where TmStamp between '{start}' and '{end}';\")\n",
    "          data = []\n",
    "          for row in cursor:\n",
    "               data.append(row)\n",
    "          num_fields = len(cursor.description)\n",
    "          field_names = ([i[0] for i in cursor.description])\n",
    "          df2 = pd.DataFrame(data, columns=[field_names])\n",
    "          df2.columns = df2.columns.get_level_values(0)\n",
    "          df2.index = pd.to_datetime(df2['tmstamp'])\n",
    "          df2.index = df2.index.tz_localize('America/Chicago', ambiguous=True, nonexistent='shift_forward')\n",
    "          df2.drop(columns='tmstamp', inplace=True)\n",
    "\n",
    "     final_df = df1.merge(right=df2, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "     return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d32f0-b1e6-473f-942c-d44288079545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
